{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dileepb0503/dileepb0503/blob/main/movieRecommendation_ContentBasedFiltering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpDLEzh61UMn"
      },
      "source": [
        "#Content-based filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-q3HvVd19kh"
      },
      "source": [
        "##Content based filtering is more specific to a user as it takes into consideration the viewer's previous activity & ratings given by user to different movies\n",
        "##The goal is to look at movies the user liked and recommend similar ones based on genre,cast,crew(director,music diector etc.),title,tagline etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7Krh9FL1ejz"
      },
      "source": [
        "###![](https://i1.wp.com/astig.ph/wp-content/uploads/2016/01/netflix-philippines-catalog.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrdYhF6U3Vxz"
      },
      "source": [
        "##Importing libraries and loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJaXyJOD0vIO",
        "outputId": "cb8c7cd2-edcb-46ac-ace5-9389faebff59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ipySNHC3CEt",
        "outputId": "49d9e6ae-82e2-4ca5-8361-12e83b2a7423"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "movies=pd.read_csv(\"/content/drive/MyDrive/movies_data/tmdb_5000_movies.csv/tmdb_5000_movies.csv\")\n",
        "credits=pd.read_csv(\"/content/drive/MyDrive/movies_data/tmdb_5000_credits.csv/tmdb_5000_credits.csv\")\n",
        "print(movies.shape,credits.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4803, 20) (4803, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L530F9gx3yVC"
      },
      "source": [
        "##Data preprocessing & visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDkFMpoT3ElU",
        "outputId": "c3f78209-17c7-42a8-f72a-e94c71899d01"
      },
      "source": [
        "#rename movie-id to id so as to merge both on the id\n",
        "credits.rename(columns={\"movie_id\":\"id\"},inplace=True)\n",
        "movies= movies.merge(credits,on='id')\n",
        "print(movies.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4803, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dqriy_-KnNT",
        "outputId": "b77d9d2d-9623-4476-fa98-c9c3c8b78468"
      },
      "source": [
        "relevant_cols=[\"id\",\"title_x\",\"genres\",\"popularity\",\"vote_average\",\"vote_count\",\"cast\",\"crew\",\"keywords\"]\n",
        "movies=movies.loc[:,relevant_cols]\n",
        "movies.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4803, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIvnpafi4Cx8",
        "outputId": "4862e68e-269a-49e7-b099-61164d369d13"
      },
      "source": [
        "movies.rename(columns={\"title_x\":\"title\",\"vote_average\":\"rating\"},inplace=True)\n",
        "print(movies.columns)\n",
        "movies.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['id', 'title', 'genres', 'popularity', 'rating', 'vote_count', 'cast',\n",
            "       'crew', 'keywords'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4803, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CkDncqS4IUm"
      },
      "source": [
        "Lets make a note of features which are critical to examining similarity of movies:\n",
        "\n",
        "\n",
        "\n",
        "1)keywords\n",
        "\n",
        "2)title\n",
        "\n",
        "3)genre\n",
        "\n",
        "4)cast\n",
        "\n",
        "5)crew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFcNaJbmBhf_"
      },
      "source": [
        "Firstly,let's convert the keywords,title to a bag of words with tokenisation,stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCiv9eNT4Fte",
        "outputId": "aac580d9-0fc9-47f1-85b7-0fd71e9e72a8"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "row_id=int((100*random.random())//1)                          #sample the keywords of this movie\n",
        "sample=movies.loc[row_id,'keywords']\n",
        "#split into words\n",
        "tokens = word_tokenize(sample)\n",
        "#tokens simply mean that words are broken into their prefixes eg.happiness,happy,happily would all tokenize to happi\n",
        "# remove all tokens that are not alphabetic(eg.punctuation,numbers etc.)\n",
        "words = [word for word in tokens if word.isalpha()]\n",
        "words=list(set(words))\n",
        "if('id' in words):\n",
        "  words.remove('id')\n",
        "if('name' in words):\n",
        "  words.remove('name')\n",
        "#Now,lets remove stopwords i.e. common words like I,am,he,it,on etc. which don't contribute much to the meaning of the sentence\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "filtered_words=[]\n",
        "for w in words:\n",
        "  if w not in stop_words:\n",
        "    filtered_words.append(w)\n",
        "print(\"The keywords of the movie:\",movies.loc[row_id,'title'],\"are\",str(filtered_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The keywords of the movie: Batman v Superman: Dawn of Justice are ['comic', 'super', 'revenge', 'bruce', 'wayne', 'based', 'powers', 'dc', 'comics', 'book', 'extended', 'clark', 'universe', 'kent', 'vigilante', 'superhero']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9qX5reSA1rb",
        "outputId": "b2b9a1c1-81c0-4124-d53e-244ef3ccee34"
      },
      "source": [
        "#Now,lets create a function for genreating a list of key_words from the keywords string\n",
        "def get_keywords(keywords):\n",
        "  tokens = word_tokenize(keywords.lower())\n",
        "  #tokens simply mean that words are broken into their prefixes eg.happiness,happy,happily would all tokenize to happi\n",
        "  #remove all tokens that are not alphabetic(eg.punctuation,numbers etc.)\n",
        "  words = [word for word in tokens if word.isalpha()]\n",
        "  words=list(set(words))\n",
        "  if('id' in words):\n",
        "    words.remove('id')\n",
        "  if('name' in words):\n",
        "    words.remove('name')\n",
        "  #Now,lets remove stopwords i.e. common words like I,am,he,it,on etc. which don't contribute much to the meaning of the sentence\n",
        "  stop_words=set(stopwords.words(\"english\"))\n",
        "  filtered_words=[]\n",
        "  for w in words:\n",
        "    if w not in stop_words:\n",
        "      filtered_words.append(w)\n",
        "  return filtered_words\n",
        "\n",
        "def get_title(title):\n",
        "  tokens = word_tokenize(title.lower())\n",
        "  #tokens simply mean that words are broken into their prefixes eg.happiness,happy,happily would all tokenize to happi\n",
        "  #remove all tokens that are not alphabetic(eg.punctuation,numbers etc.)\n",
        "  words = [word for word in tokens if word.isalpha()]\n",
        "  words=list(set(words))\n",
        "  #Now,lets remove stopwords i.e. common words like I,am,he,it,on etc. which don't contribute much to the meaning of the sentence\n",
        "  stop_words=set(stopwords.words(\"english\"))\n",
        "  filtered_words=[]\n",
        "  for w in words:\n",
        "    if w not in stop_words:\n",
        "      filtered_words.append(w)\n",
        "  return filtered_words\n",
        "\n",
        "#lets test these functions\n",
        "row_id=int((100*random.random())//1)\n",
        "print(\"Title:\",movies.loc[row_id,\"title\"],'| Title(bag of words)',str(get_title(movies.loc[row_id,\"title\"])),'| keywords(bag of words)',str(get_keywords(movies.loc[row_id,\"keywords\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: Independence Day: Resurgence | Title(bag of words) ['independence', 'day', 'resurgence'] | keywords(bag of words) ['invasion', 'history', 'alternate', 'alien']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HekU3G7wVS7R"
      },
      "source": [
        "#The genre and cast are string type first lets make functions to convert them to dictionaries\n",
        "def process_genre(s):\n",
        "  id_str=s.split(\", \")[0]\n",
        "  genre_str=s.split(\", \")[-1]\n",
        "  genre={}\n",
        "  genre[\"id\"]=int(id_str.split(':')[-1])\n",
        "  genre[\"name\"]=(genre_str.split(':')[-1])[2:-1]\n",
        "  return genre\n",
        "\n",
        "def get_genres(s):\n",
        "  if(len(s)<5):\n",
        "    return {}\n",
        "  genres=s.split(\"}, {\")\n",
        "  genres[0]=genres[0][2:]\n",
        "  genres[-1]=genres[-1][:-2]\n",
        "  genre_dicts=[]\n",
        "  for genre in genres:\n",
        "    genre_dicts.append(process_genre(genre))\n",
        "  return genre_dicts\n",
        "\n",
        "def process_actor(s):\n",
        "  id_str=s.split(\", \")[0]\n",
        "  actor_str=s.split(\", \")[-2]\n",
        "  actor={}\n",
        "  actor[\"id\"]=int(id_str.split(':')[-1])\n",
        "  actor[\"name\"]=(actor_str.split(':')[-1])[2:-1]\n",
        "  return actor\n",
        "\n",
        "def get_cast(s):\n",
        "  if(len(s)<5):\n",
        "    return {}\n",
        "  cast=s.split(\"}, {\")\n",
        "  cast[0]=cast[0][2:]\n",
        "  cast[-1]=cast[-1][:-2]\n",
        "  cast_dicts=[]\n",
        "  for actor in cast:\n",
        "    cast_dicts.append(process_actor(actor))\n",
        "  return cast_dicts\n",
        "\n",
        "def process_crew(s):\n",
        "  id_str=s.split(\", \")[-3]\n",
        "  job_str=s.split(\", \")[-2]\n",
        "  name_str=s.split(\", \")[-1]\n",
        "  crew={}\n",
        "  crew[\"id\"]=id_str.split(':')[-1]\n",
        "  crew[\"job\"]=(job_str.split(':')[-1])[2:-1]\n",
        "  crew[\"name\"]=(name_str.split(':')[-1])[2:-1]\n",
        "  return crew\n",
        "\n",
        "def get_crew(s):\n",
        "  #only director seems relevant we can safely ignore others like cameraman,producer,dubbing artist etc.\n",
        "  if(len(s)<5):\n",
        "    return {}\n",
        "  crew=s.split(\"}, {\")\n",
        "  crew[0]=crew[0][2:]\n",
        "  crew[-1]=crew[-1][:-2]\n",
        "  crew_dicts=[]\n",
        "  for crew_member in crew:\n",
        "    crew_dicts.append(process_crew(crew_member))\n",
        "  return crew_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGpjSnQ4VSX5",
        "outputId": "e03b1870-b75d-41f0-c639-6df8ab2fe125"
      },
      "source": [
        "#now,lets make cast,genre and crew list\n",
        "\n",
        "def get_genre_list(s):\n",
        "  genre_dicts=get_genres(s)\n",
        "  genre_list=[genre[\"name\"] for genre in genre_dicts]\n",
        "  return genre_list\n",
        "\n",
        "def get_cast_list(s):\n",
        "  cast_dicts=get_cast(s)\n",
        "  cast_list=[actor[\"name\"] for actor in cast_dicts]\n",
        "  return cast_list\n",
        "\n",
        "def get_crew_list(s):\n",
        "  crew_dicts=get_crew(s)\n",
        "  crew_list=[crew_member[\"name\"] for crew_member in crew_dicts if crew_member[\"job\"]==\"Director\"]\n",
        "  return crew_list\n",
        "\n",
        "get_crew_list(movies.loc[3,\"crew\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Christopher Nolan']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKk0Ufzrf7ni"
      },
      "source": [
        "Now lets test all these lists for a movie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6k61iItgG1u",
        "outputId": "2cf4ddb8-aaa5-473c-8021-d41ca3f10ed9"
      },
      "source": [
        "row_id=int((100*random.random())//1)\n",
        "print(\"TITLE:\",movies.loc[row_id,\"title\"])\n",
        "print(\"KEYWORDS:\",str(get_keywords(movies.loc[row_id,\"keywords\"])))\n",
        "print(\"GENRES:\",str(get_genre_list(movies.loc[row_id,\"genres\"])))\n",
        "print(\"CAST:\",str(get_cast_list(movies.loc[row_id,\"cast\"])))\n",
        "print(\"DIRECTOR:\",str(get_crew_list(movies.loc[row_id,\"crew\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TITLE: 47 Ronin\n",
            "KEYWORDS: ['based', 'true', 'breed', 'japan', 'story', 'half', 'sword', 'shogun', 'samurai', 'suicide', 'ronin']\n",
            "GENRES: ['Drama', 'Action', 'Adventure', 'Fantasy']\n",
            "CAST: ['Keanu Reeves', 'Hiroyuki Sanada', 'Kou Shibasaki', 'Tadanobu Asano', 'Min Tanaka', 'Rinko Kikuchi', 'Jin Akanishi', 'Masayoshi Haneda', 'Hiroshi Sogabe', 'Takato Yonemoto', 'Sh\\\\u00fb Nakajima', 'Hiroshi Yamada', 'Cary-Hiroyuki Tagawa', 'Tanroh Ishida', 'Yorick van Wageningen', 'Ron Bottitta', 'Natsuki Kunimoto', 'Togo Igawa', 'Akira Koieyama', 'Haruka Abe', 'Clyde Kusatsu', 'Junichi Kajioka', 'Masashi Fujimoto', 'Neil Fingleton']\n",
            "DIRECTOR: ['Carl Rinsch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dtF4U8JjTes"
      },
      "source": [
        "Now,let's develop a similarity measure between any 2 arbitary movies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkQZ3WaRjShm"
      },
      "source": [
        "def get_sim(list1,list2):\n",
        "  ctr=0\n",
        "  for ele in list1:\n",
        "    if ele in list2:\n",
        "      ctr+=1\n",
        "  return ctr/len(list1)\n",
        "\n",
        "def get_similarity(i,j):\n",
        "  #let's the get the features of movies in row i\n",
        "  past_title=get_title(movies.loc[i,\"title\"])\n",
        "  past_keywords=get_keywords(movies.loc[i,\"keywords\"])\n",
        "  past_genres=get_genre_list(movies.loc[i,\"genres\"])\n",
        "  past_cast=get_cast_list(movies.loc[i,\"cast\"])\n",
        "  past_directors=get_crew_list(movies.loc[i,\"crew\"])\n",
        "  #Now,lets get the features of movie at row j\n",
        "  present_title=get_title(movies.loc[j,\"title\"])\n",
        "  present_keywords=get_keywords(movies.loc[j,\"keywords\"])\n",
        "  present_genres=get_genre_list(movies.loc[j,\"genres\"])\n",
        "  present_cast=get_cast_list(movies.loc[j,\"cast\"])\n",
        "  present_directors=get_crew_list(movies.loc[j,\"crew\"])\n",
        "  similarity=0\n",
        "  weights=[5,5,3,10,2]\n",
        "  similarity+=weights[0]*get_sim(past_title,present_title)\n",
        "  similarity+=weights[1]*get_sim(past_keywords,present_keywords)\n",
        "  similarity+=weights[2]*get_sim(past_genres,present_genres)\n",
        "  similarity+=weights[3]*get_sim(past_cast,present_cast)\n",
        "  similarity+=weights[4]*get_sim(past_directors,present_directors)\n",
        "  return similarity/sum(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omrJNLr2MEBL"
      },
      "source": [
        "def get_rowId(movie):\n",
        "  for row_id in range(movies.shape[0]):\n",
        "    if(movie==movies.loc[row_id,\"title\"]):\n",
        "      return row_id\n",
        "  return -1\n",
        "\n",
        "def get_recommendation(watch_history,rating_history=-1):\n",
        "  #Here,watch_history is list of previous movies & rating_history is the corresponding rating given by the user(if no rating were given feed -1)\n",
        "  similarity_scores=np.zeros((movies.shape[0],len(watch_history)))\n",
        "  rowIds=[]\n",
        "  for past_movie in watch_history:\n",
        "    row_id=get_rowId(past_movie)\n",
        "    rowIds.append(row_id)\n",
        "  for idx,past_movie_id in enumerate(rowIds):\n",
        "    for row_id in range(movies.shape[0]):\n",
        "      if row_id not in rowIds:\n",
        "        similarity_scores[row_id,idx]=get_similarity(past_movie_id,row_id)\n",
        "  cummulative_similarity_score=np.dot(similarity_scores,np.array(rating_history))\n",
        "  #Recommend movies with Top 10 cummulative similarity scores\n",
        "  recommended_rowIds=np.flip(cummulative_similarity_score.argsort()[-20:])\n",
        "  top_movies=movies.loc[recommended_rowIds,:]\n",
        "  recommendations=list(top_movies.nlargest(10,'popularity').loc[:,'title'])\n",
        "  print(\"****TOP PERSONALIZED RECOMMENDATIONS****\")\n",
        "  for idx,movie in enumerate(recommendations):\n",
        "    print(idx+1,')',movie)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHUOgi7Eq1IL",
        "outputId": "2884e438-2a89-48af-a338-99b450d0e429"
      },
      "source": [
        "get_recommendation([\"Mission: Impossible\",\"Insidious\"],[5,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****TOP PERSONALIZED RECOMMENDATIONS****\n",
            "1 ) Mission: Impossible - Rogue Nation\n",
            "2 ) Mission: Impossible - Ghost Protocol\n",
            "3 ) Scarface\n",
            "4 ) Mission: Impossible III\n",
            "5 ) Mission: Impossible II\n",
            "6 ) Dr. No\n",
            "7 ) Tomorrow Never Dies\n",
            "8 ) From Russia with Love\n",
            "9 ) Ronin\n",
            "10 ) Live and Let Die\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO-XGco6xgpk",
        "outputId": "975623ae-ce69-4c04-976d-88591e22ef69"
      },
      "source": [
        "get_rowId(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0m0PTOqO6MG",
        "outputId": "1a1fd353-4518-4475-9578-96293d348620"
      },
      "source": [
        "print(movies.loc[:100,\"title\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                        Avatar\n",
            "1      Pirates of the Caribbean: At World's End\n",
            "2                                       Spectre\n",
            "3                         The Dark Knight Rises\n",
            "4                                   John Carter\n",
            "                         ...                   \n",
            "96                                    Inception\n",
            "97                                Shin Godzilla\n",
            "98            The Hobbit: An Unexpected Journey\n",
            "99                     The Fast and the Furious\n",
            "100         The Curious Case of Benjamin Button\n",
            "Name: title, Length: 101, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYp87N52PolK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}